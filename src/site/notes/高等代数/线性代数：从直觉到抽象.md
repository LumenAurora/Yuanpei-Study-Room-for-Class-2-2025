---
{"dg-publish":true,"permalink":"/高等代数/线性代数：从直觉到抽象/"}
---

# 如何理解
线性结构、线性组合为核心，行与列、空间（静态）与映射（动态）双重视角。
代数直觉（AI教科书）：从数据角度，向量就是一个list，矩阵就是把多个list拼在了一起（横着是一组数据，竖着是所有数据的同一属性）。而从作用角度，矩阵集约表示了组合不同属性所需要的各个系数，可以一次性计算的多组数据的值。因此，通过这套语言，我们可以把在一个自变量成立的公式拓展到多个自变量，而不改变形式。
几何直觉（3b1b）：从二维、三维这种低维线性映射作为例子来理解，关注基变换，即一个矩阵是把行空间标准正交基映射到列空间的过程，为了减省往往都使用方阵来理解，因此就简化为对空间的线性变形，比如旋转、剪切之类的，能够很好地解释特征值、正交矩阵等本来就要求是方阵的部分。
工科学法（Gilbert Strong《An Introduction to Linear Algebra》）：围绕工科中常用的运算作为例子详细展开，阐述每个例子能够体现出的全部理论。静态部分-解线性方程组LU分解，最小二乘法。动态部分-解微分方程组（特征值），奇异值分解。基视角（对线性以及基向量线性组合的认识，推广到无限维空间）-正交基对应的傅里叶变换等。
理科学法（Alex《Linear Algebra Done Right》）：线性代数是研究由有限维向量空间上的线性映射的学问，符合代数学研究“态射”的思想。在向量空间选定基底后，向量与坐标同构，线性映射与矩阵同构。这时，我们要先理解什么是基底，对于一般的基底选择矩阵会有怎样的性质；然后是研究好的基底选择，再查看会发生什么。对于线性映射，我们也要先研究一般的线性映射（线性映射总有作用对象），再研究一些特殊的、好的线性映射。注意符号重载，基底也可以写成矩阵的形式，可以理解为由标准基变换到目前的基。用抽象代数方式学习，一定要确保梳理清晰概念的关系、依赖关系、生成关系。值得注意的是，映射本身也可构成一个线性空间，便于理解，很多映射可以用一组参数描述，而关于这一组参数结构是线性的。
# 线性变换
- **可分解性**：线性运算的最大特色之一是能够「分而治之」——一个向量可以拆成若干基向量的线性组合，映射可以分块作用，然后再把结果加起来。矩阵的行与列正是对「把输入分块，对每块进行加权处理，再将输出组合」的坐标化实现。
- **可复合性**：在函数层面，「先做  再做 」对应的是复合 。在线性代数的世界中，这个复合操作变成了「矩阵相乘」，从而使我们能以坐标代数的方法去处理诸多连续或分步的线性操作。
- **可叠加性**：世界上大量的自然、物理和工程系统可以（或至少在局部）用线性模型表示，因为它们（暂时）满足叠加原理。在这个意义下，矩阵乘法成为了描述这些「叠加演化」最顺手的工具。
- **不变性**：矩阵乘法之下的一系列不变量（迹、行列式、特征值谱……）往往对应某些深层对称或守恒定律；物理学中会关心质量、能量、动量的守恒；在数学中会关心度量、对称性、正交性的保持。
线性变换要求原点不变，加入平移后成为仿射变换，仿射变换可通过升维为含齐次坐标的增广矩阵来描述。
# 矩阵乘法的N种理解
矩阵乘法 Ax 的本质是将行空间中的向量 x 通过列向量的线性组合映射到列空间中。具体来说，行空间由矩阵的行向量张成，列空间由矩阵的列向量张成。当用矩阵 A 乘以一个行空间中的向量 x 时，结果 Ax 是列空间中的向量，因为它是列向量的线性组合。你想想维数匹配这件事就很显然了。1. 如果 x 在行空间中，那么 Ax 就是列空间中的向量。2. 如果 x 不在行空间中，但可以分解为行空间和零空间中的部分，即 x=xrow​+xnull​，其中 xrow​ 是行空间中的部分，xnull​ 是零空间中的部分。这时： Ax=A(xrow​+xnull​)=Axrow​+Axnull​  根据零空间的定义，Axnull​=0，所以最终结果 Ax=Axrow​。这似乎说明：无论 x 是否超出行空间，Ax 的结果都等价于其行空间部分的映射结果。这就是行空间涉及到的投影。四个空间大有用啊，因为正交会牵扯出投影，有了投影就有分解！线性无关组的分解非常重要，代数化之后抽象证明能弥补直观的不足。
$$
1. 先固定一组“行基”  
取 Row(A) 的一组正交基  
  {q₁,…,qᵣ} ⊂ ℝⁿ， r = dim Row(A)。  
把 A 的每一行在这组基下展开：

  aᵢᵀ = Σ_{k=1}^{r} c_{ik} qₖᵀ， i = 1…m.  (1)

系数矩阵 C = [c_{ik}] ∈ ℝ^{m×r} 只与 A 有关，与 x 无关。

-------------------------------------------------
2. 第一步回顾——“行坐标” s  
对任意 x∈ℝⁿ，令

  sₖ = qₖᵀx， k = 1…r.  (2)

则 s = (s₁,…,sᵣ)ᵀ ∈ ℝʳ 就是 x 在行空间里的坐标。  
由(1)(2)立刻得到

  aᵢᵀx = Σ_{k=1}^{r} c_{ik} sₖ.  (3)

-------------------------------------------------
3. 第二步——“把坐标堆回 ℝᵐ”  
把(3)按 i = 1…m 排成列向量，得

  Ax = [ a₁ᵀx ]  
    [  ⋮   ]  
    [ aₘᵀx ]  
   = C s.  (4)

这就是**纯行视角**下的“堆叠”：  
- 左边 Ax 是 m 维输出；  
- 右边 C∈ℝ^{m×r} 只由“行基展开系数”组成；  
- s∈ℝʳ 是第一步给出的“行空间坐标”。  

(4)式表明：  
像空间 Im(A) = { C s | s∈ℝʳ } = Im(C).  (5)

-------------------------------------------------
4. 维数清点  
- C 的列向量是 r 个 m 维向量，故 rank(C) ≤ r；  
- 但 C 的列线性无关：若 Cλ = 0，则对任意 x 取 s = λ 可得 A x = 0，即 λ 对应的行空间向量落在 N(A)；而 Row(A) ∩ N(A) = {0}，故 λ = 0。  
因此 rank(C) = r。  

由(5)得  
  列秩 = dim Im(A) = dim Im(C) = r = 行秩。  

-------------------------------------------------
一句话总结第二步：  
“先拿行基把 x 压缩成 r 个数 s，再用同一套展开系数矩阵 C 把 s 重新摊回 m 维空间——这个摊回动作就是 Ax，而它的像维数显然等于 r，于是列秩只能等于行秩。”
$$
最经典，aij=前行点乘后列；与之相对的，用外积角度，对应地前列i外积后行i得到的秩为1的矩阵全部相加。等效为向量乘矩阵，矩阵左乘列向量得到每一列，矩阵右乘行向量得到每一行。
对于证明题，结合律非常重要。简而言之，AB的每一列可以理解为A的每一列的线性组合，每一行是B的每一行的线性组合。
点积的集约写法：$\begin{aligned} a_1^T (b - A\hat{x}) &= 0 \\ &\vdots \\ a_n^T (b - A\hat{x}) &= 0 \end{aligned}$ 或 $\begin{bmatrix} - & a_1^T & - \\ & \vdots & \\ - & a_n^T & - \end{bmatrix} \begin{bmatrix} b - A\hat{x} \end{bmatrix} = \begin{bmatrix} 0 \end{bmatrix}$ 
2. 矩阵 $A$ 乘 ($B$ 的每一列) $A[b_1 \ldots b_p] = [Ab_1 \ldots Ab_p]$ 行图恰好相反，是 ($A$ 的每一行) 乘整个 $B$，结果就是 $AB$ 的一个行。$AB$ 的每一行都是 ($B$ 的行) 的组合: 3. ($A$ 的每一行) 乘矩阵 $B$ $\begin{bmatrix} A \text{ 的行 } i \end{bmatrix} \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix} = \begin{bmatrix} AB \text{ 的行 } i \end{bmatrix}$ 我们在消元法看到行运算 ($E$ 乘 $A$)，很快的我们会看到 $AA^{-1} = I$ 的列。“行-列图”有行与列的点积，手算矩阵乘法时经常使用点积: $mnp$ 次个别乘法/加法的步骤。 $AB = (m \times n)(n \times p) = (m \times p)$ $mp$ 次点积，每次点积需要 $n$ 个步骤
# 行列式的N种理解
行列式的每一项使用每个行和列一次。
求解方法-往前看 $n \times n$ 矩阵的行列式有 3 种方法求得： 1. $n$ 个主元的乘积(乘 1 或 -1) 这是主元公式 $(\det P)(\det A) = (\det L)(\det U)$ 得到 $\det A = \pm (d_1 d_2 \ldots d_n)$ 2. $n!$ 项的总和(乘 1 或 -1) 这是“大公式”-可以利用一个大行列式可以拆成多个有一个格填0的行列式的求和，排除值为0的行列式 3. 组合 $n$ 个较小的行列式(乘 1 或 -1) 这是余子式公式
三种应用：(1) 行列式产生$A^{-1}$与$A^{-1}b$（这个公式称为克拉默规则）。A-1=CT/(detA)，A的行乘上来自不同行的余子式结果是0，这是因为它的运算结果等价于把第二行复制到第一行然后计算，有重复行就是0(2) 当盒子的边是$A$的行，体积是$|\det A|$。 (3) 存在$n$个特殊数字$\lambda$称为特征值(eigenvalue)，$A - \lambda I$的行列式是0。这是非常重要的应用。特征值构成第六章。
注意线性运算性质别理解错了。3 行列式对于个别的行是线性函数(其他行保持固定)。 如果用$t$乘第一行，$t$也会乘行列式。如果第一行是相加，行列式也是相加。只有当其他行保持不变时，这个规则才能适用。注意$c$与$d$如何保持不变: 任意数$t$乘行1，$t$乘行列式 $\begin{vmatrix} ta & tb \\ c & d \end{vmatrix} = t \begin{vmatrix} a & b \\ c & d \end{vmatrix}$ $A$的行1与$A'$的行1相加，行列式相加: $\begin{vmatrix} a + a' & b + b' \\ c & d \end{vmatrix} = \begin{vmatrix} a & b \\ c & d \end{vmatrix} + \begin{vmatrix} a' & b' \\ c & d \end{vmatrix}$ 
对于$n \times n$的案例来说，此处有一个简洁的方法可以证明$|AB| = |A||B|$。当$|B| \neq 0$，考虑比值$D(A) = \frac{|AB|}{|B|}$。检查比值$D(A)$具有性质1, 2, 3，则$D(A)$必须是行列式且我们有$\frac{|AB|}{|B|} = |A|$。赞。
# 工科实例视角
本章加入线性代数的新内容，第一部分是有关$Ax = b$: 平衡与均衡与稳定状态，解方程问题串起了初等行变换-高斯消元法-主元和秩-LU分解-逆矩阵（扩展一个I）-最小二乘法-正交性简化QR分解。现在第二部分是有关改变，时间进入蓝图——连续时间的微分方程式$\frac{du}{dt} = Au$或是离散方程式的$u_{k+1} = Au_k$，这些方程式无法由消元求解。 关键概念在于避免矩阵$A$带来复杂性，假设解向量$u(t)$保持在固定向量$x$的方向，我们只需要找出乘$x$的数字(随时间变化)，一个数字比一个向量容易。我们希望特征向量(eigenvector)$x$在被$A$乘时不会改变方向。
# 几何视角
## 向量空间
每个向量空间的子空间必须包含零向量。
## 矩阵与线性变换
### 用基的变换掌控线性变换
矩阵描述了针对基的变换的过程，每一列代表原来标准基变换到的新坐标（标准基确保了没有列之间的偶联），因此描述一个几何变换只要紧盯基的变换过程即可。从动态来讲，可以理解为标准基变换为非标准基的过程。
在矩阵分解的领域中，一个矩阵的列空间也可以描述着线性空间中的一组基（变换过程的最终结果），静态理解也可以。
### 基变换，坐标变换
[(4 封私信 / 82 条消息) 通俗易懂：基变换和坐标变换 - 知乎](https://zhuanlan.zhihu.com/p/683873038)
两套基之间的变换：
1**自然基变换为非自然基**：即矩阵描述的本身
2**非自然基变换为自然基**：即逆矩阵描述的本身
3**非自然基变换为非自然基**：因为：M×P=E，E×N=N，所以：M×P×N = N  也就是M×P先转为自然基，在此基础上再转非自然基N，转换矩阵就是$M^{-1}N$。
两套基之间的变换矩阵称为过渡矩阵，由于基的定义包含线性无关的性质，因此过渡矩阵是满秩的，这种变换是可逆的。基变换矩阵的「方向」指的是：它把一个向量的坐标从某个基的表示法，转换（变换）到另一个基的表示法。
坐标变换：自然基理解。或者用$M[x]_M=N[x]_N=MP[x]_N$ 算一下就行（矩阵分解是证明题中的重要过渡）![高等代数/attachments/Pasted image 20250703104857.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250703104857.png)
折让我们注意到，从标准基变换到非自然基是变换矩阵，但是针对同一向量（由同一性的等式支配），从标准基表示变换到非自然基表示是变换矩阵的逆矩阵，这就是坐标变换的补偿感觉。因此，在理解各种矩阵的分解方式时，请务必使用坐标变换的思维。
![高等代数/attachments/Pasted image 20250703110614.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250703110614.png)
![高等代数/attachments/Pasted image 20250912224618.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250912224618.png)
如针对方阵的相似对角化-关注的是那些**方向保持不变**的向量：![高等代数/attachments/Pasted image 20250703110400.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250703110400.png)
![高等代数/attachments/Pasted image 20250912224728.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250912224728.png)
https://mp.weixin.qq.com/s/xbyETzlCGddhbhVn-7Ybvg
![高等代数/attachments/Pasted image 20250912233602.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250912233602.png)
注意谈特征值一定得是方阵，因为不变子空间必须是空间类型不变。因为我们不能假定两个线性空间有任何关系。“不变子空间”这个概念是为**线性算子**（从空间到自身的映射）定义的。
相似：同一个线性变换T，在标准基下的矩阵A和在任意基下的矩阵$T_B$是**相似 (Similar)** 的，它们通过基变换矩阵$P=P_B$联系起来，这个过程是$T_b=P^{-1}AP$，刚好理解为坐标变换，先把任意基变成标准基，执行A变换，再变回任意基。
计算流程-以矩阵语言来说，$A^k$等于$(X\Lambda X^{-1})^k$，也就是$X$乘$\Lambda^k$乘$X^{-1}$。在步骤1，$X$的特征向量得到组合$\boldsymbol{u}_0 = c_1 \boldsymbol{x}_1 + ... + c_n \boldsymbol{x}_n$的$c's$: 步骤 1 $\quad \boldsymbol{u}_0 = \begin{bmatrix} \boldsymbol{x}_1 & ... & \boldsymbol{x}_n \end{bmatrix} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}$ 表示 $\boldsymbol{u}_0 = Xc$ (12) 步骤1的系数是$c = X^{-1}\boldsymbol{u}_0$。然后步骤2左乘$\Lambda^k$，步骤3的最终结果$\boldsymbol{u}_k = \sum c_i (\lambda_i)^k \boldsymbol{x}_i$是$X$与$\Lambda^k$与$X^{-1}\boldsymbol{u}_0$的乘积: $A^k \boldsymbol{u}_0 = X\Lambda^k X^{-1} \boldsymbol{u}_0 = X\Lambda^k c = \begin{bmatrix} \boldsymbol{x}_1 & ... & \boldsymbol{x}_n \end{bmatrix} \begin{bmatrix} (\lambda_1)^k & & \\ & \ddots & \\ & & (\lambda_n)^k \end{bmatrix} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}$ (13) 这个结果恰好是$\boldsymbol{u}_k = A^k \boldsymbol{u}_0 = c_1 (\lambda_1)^k \boldsymbol{x}_1 + ... + c_n (\lambda_n)^k \boldsymbol{x}_n$，是$\boldsymbol{u}_{k+1} = A\boldsymbol{u}_k$的解。这个计算流程也可应用于一阶线性齐次常系数微分方程组，只需要将特征值改为e^(lambda * t)。
主成分分析PCA：通过拉格朗日乘子可以证明（约束是目标向量的模长为1，最值是投影之后的方差最大），方差贡献最大的方向就是协方差矩阵特征向量所在方向。
奇异值分解-关注的是那些变换前后都**保持正交**的两个标准正交基：无论线性变换的矩阵是什么样子的，单位球变换后的结果总是一个椭球（或其降维形式）。椭球有主轴，这些主轴的方向和长度是变换的关键特征。椭圆的新主轴方向和长度正好对应于矩阵  的奇异值分解（SVD）中的主轴，其方向由左奇异向量（U的列向量）决定，长度由奇异值给出。任何线性变换都将输入空间中的一个标准正交基（右奇异向量）映射到输出空间中的一个标准正交基（左奇异向量）的缩放版本（缩放因子是奇异值）。输入空间的圆（球）→ 旋转对齐主轴 → 缩放成椭圆（椭球）→ 旋转到输出空间的方向。
我想要介绍特征向量的用途，但是大部分图像的特征向量不是正交。此外，特征向量$x_1$与$x_2$只给出一个向量集合，而我们需要两个集合($u's$与$v's$)。这两个困难的答案正是SVD的概念: 使用$AA^T$的特征向量$u$与$A^TA$的特征向量$v$。
$\lambda_1 = \text{极大比值} \frac{x^T S x}{x^T x}$，致胜向量是$x = q_1$且$S q_1 = \lambda_1 q_1$ (8) 比较$A$的最大奇异值$\sigma_1$，它解答了下列问题: $\sigma_1 = \text{极大比值} \frac{\|Ax\|}{\|x\|}$，致胜向量是$x = v_1$且$A v_1 = \sigma_1 u_1$ (9)
PCA 设定了「我要找到最大方差的方向」这个**目标**，并通过「计算协方差矩阵的特征向量」这个**数学路线**来实现；而 SVD 提供了一种强大的**计算工具**，它可以**不用计算协方差矩阵**（是一个比较重的操作），直接分解出这些特征向量（以右奇异向量的形式），并且在数值上通常更优越。
**谱半径**：指的是矩阵所有特征值绝对值的最大值，它反映了矩阵对向量的最大放大效应。
### 正交与投影
格拉姆 - 施密特正交化过程：逐个处理原始基向量，对于每个新的向量，减去它在已经正交化好的向量所张成子空间上的投影，剩下的部分就与之前的向量正交了。
最小二乘法：找到无解线性方程组Ax=b的最佳逼近解，即列空间中距离目标向量最近的点。正规方程：1$A^T(b-A\hat{x})=0$ 2$A^TA\hat{x}=A^Tb$ ，当ATA可逆的时候，解为$\hat{x}=(A^TA)^{-1}A^Tb$ 
投影矩阵P：最小二乘法的过程就是在找一个向量在子空间的投影向量。$\hat{y}=A(A^TA)^{-1}A^Tb$ 
2x2P有以下性质：1. 马尔可夫矩阵：$P$的每个列总和是1，所以$\lambda = 1$是一个特征值。 2. $P$是奇异，所以$\lambda = 0$是一个特征值。 3. $P$是对称，所以它的特征向量$(1, 1)$与$(1, -1)$垂直。直观上很好理解，一个方向不变，另一个垂直投影到这个方向、就压缩没了。
用矩阵写最小二乘的好处在于矩阵是通用的语言，可以适配于任何类似地关于参数空间线性的拟合，比如傅里叶、抛物线等等，它只是把多条投影方程合在一起写了，帮助抽象推广。
![高等代数/attachments/Pasted image 20250909105924.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250909105924.png)
将投影思想用到炉火纯青
![高等代数/attachments/Pasted image 20250912223925.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250912223925.png)
正交矩阵：求逆=求转置。最小二乘法有非常好的形式
$\begin{aligned} b = q_1 (q_1^T b) + \ldots + q_n (q_n^T b) \end{aligned}$ 转换 $QQ^T = I$ 是傅里叶级数的基础，也是所有应用数学中伟大“转换”的基础。他们把 $\boldsymbol{b}$ 或函数 $f(x)$ 打碎成为垂直的片段，借由(6)中的片段，逆转换把 $\boldsymbol{b}$ 与 $f(x)$ 再次一起恢复。
### 维度
rank、零空间、det=0（矩阵是奇异的）、线性相关代表了变换是否丢失维度信息，一旦降维则不可逆。
## 解方程组
对于解方程组来说，由于每一列都代表着一种数据集合的属性（比如一只鸡有两只脚），因此用矩阵写更为凝练。有解性即目标向量是否落在列空间中，解是否唯一则看零空间是否只包括零向量本身。从行空间视角，每一条方程代表了一个超平面，解是超平面相交的部分，高斯消元法即不改变交集的情况下简化矩阵形式（交换行顺序显然不影响，某一行乘倍数显然只是超平面方程齐次缩放、不影响，而行之间的加减操作则是曲线系的思想、加减交点不变）。初等行变换之所以有效，当然从行的几何角度可以理解，从它本身表征的线性方程组的运算律上更能直观地理解，可见曲线系的本质就是代数的联立，几何和代数是等价的。
## 初等行变换与高斯消元法：
- 交换两行（列）：相当于在变换后做了一次**反射**，改变方向，所以行列式**取反**。交换两行可理解为复合了一个关于y=x的反射。
- 将一行（列）乘以 ：相当于只在一个基向量方向上拉伸了k倍，所以行列式**乘以k** 。
- 将一行的倍数加到另一行（列加到另一列）：这对应于一种**剪切 (Shear)** 操作。我们知道剪切变换保持面积/体积不变（想象一摞牌被推斜，体积不变），所以这种操作**不改变**行列式的值！这正是高斯消元法计算行列式的基础。
初等行变换的过程可以揭示矩阵的许多性质。
对我来说，通过矩阵的一个动作，可以同时回答这两个问题是惊奇的。事实上这个动作得到的是三角形阶梯矩阵 $U$，而不是简化阶梯矩阵 $R$。从 $U$ 到 $R$ 的简化是由底部往顶端前进，$U$ 可以分辨哪些列是较早列的组合（丢失主元），而 $R$ 会告诉我们是什么样的组合。 换言之，$R$ 告诉我们 $Ax = 0$ 的特殊解，我们可以借由不同的行交换以及消元步骤从 $A$ 得到 $R$，但是得到的永远是同一个 $R$（因为特殊解是由 $A$ 决定）。后面的术语会很快来到，$R$ 显露了三个基础子空间的“基底(base)”： - $A$ 的列空间 - 选择 $A$ 的主元列作为基底。 - $A$ 的行空间 - 选择 $R$ 的非零行作为基底。 - $A$ 的零空间 - 选择 $Rx = 0$（与 $Ax = 0$）的特殊解。
非齐次线性方程组：若存在解，$R$ 的零行在 $d$ 也必须是 $0$。由于 $I$ 在 $R$ 的主元行与主元列，则 $x_{\text{特解}}$ 的主元变量来自 $d$:
线性方程式与秩 $r$ 相关的 4 种可能性：满列秩代表没有自由变量，列空间张满；

| 条件 | 矩阵形状 | $Ax = b$ 的解情况 |
| --- | --- | --- |
| $r = m$ 且 $r = n$ | 方形可逆 | 有 1 个解 |
| $r = m$ 且 $r < n$ | 矮且宽 | 有无限多解 |
| $r < m$ 且 $r = n$ | 高且瘦 | 有 0 个或 1 个解 |
| $r < m$ 且 $r < n$ | 非满秩 | 有 0 个或无限多解 |
通过扩展一个I，可以得到A的逆矩阵。
## 逆矩阵
- 1. $K$ 是对称，则 $K^{-1}$ 也是对称的。 2. $K$ 是三对角 (tridiagonal) 矩阵（只有 3 个非零对角线），但是 $K^{-1}$ 是一个没有 0 的浓密 (dense) 矩阵，这是另一个我们不常计算逆矩阵的原因。带状矩阵的逆矩阵通常都是浓密矩阵。
- 三角矩阵可逆当且仅当没有对角线元素为0.
- 对角式支配 (diagonally dominant) 矩阵为可逆。每个 $a_{ii}$ 比行 $i$ 其他单元的总和还要大很多，对于每一行: $\left| a_{ii} \right| > \sum_{j \neq i} \left| a_{ij} \right|$ 就是说 $\left| a_{ii} \right| > \left| a_{i1} \right| + \left| a_{i2} \right| + ... \left( \text{跳过} \left| a_{ii} \right| \right) + ... + \left| a_{in} \right|$ 【证明】 选取任意非零向量 $x$，假设它的最大分量是 $\left| x_i \right|$，当 $A$ 是对角支配矩阵时，不可能有 $Ax = 0$。因为如果 $Ax$ 的行 $i$ 为零，需要有 $a_{i1}x_1 + ... + a_{ii}x_i + ... + a_{in}x_n = 0$ 这些项的总和不可能是零！$\left| a_{ii} x_i \right|$（某个特定项）的大小比其他组合项要大很多: 所有 $\left| x_j \right| < \left| x_i \right|$ $\sum_{j \neq i} \left| a_{ij} x_j \right| \leq \left( \sum_{j \neq i} \left| a_{ij} \right| \left| x_i \right| \right) < \left| a_{ii} \right| \left| x_i \right|$ 因为 $a_{ii}$ 是支配项
## 实对称矩阵
矩阵转置后仍然等于自身，就称为对称矩阵。
性质：
- **特征值都是实数**：即使矩阵元素是实数，非对称矩阵的特征值可以是复数（如纯旋转矩阵）。但实对称矩阵的特征值总是实数，这使得分析其伸缩性质更直接。
- **不同特征值对应的特征向量相互正交**：如果对称矩阵有两个不同的特征值 ，那么它们对应的特征向量  和  一定满足 ，即它们是正交的。
- **总是可以找到一组由其特征向量构成的标准正交基来对角化它**：即使存在重复的特征值（即 **特征多项式** 具有 **重根**），我们总能在对应的特征空间中找到足够多的线性无关且相互正交的特征向量，这些特征向量可以构成整个空间的标准正交基。
- 谱定理：任何由对称矩阵表示的线性变换，都可以在其**特征向量**构成的**标准正交基**下，被分解为仅仅是沿着这些正交方向的**缩放**，缩放因子正是特征值。相似对角化升级为正交相似对角化。特征向量指着二次曲面的主轴方向，而特征值决定了曲面的形状。
通过数学表达式上的一致性，可用来表示和研究二次型。如果所有特征值全正，则为正定矩阵，对应的相当于二次型的delta恒正，有最小值点，这恰恰与优化问题（判断函数的极值点类型）紧密相关。从$Sx = \lambda x$，左乘$x^T$得到$x^TSx = \lambda x^Tx$，右侧是正数$\lambda$乘一个正数$x^Tx = \|x\|^2$，所以对于任意的特征向量，左侧的$x^TSx$是正数。
线性代数中的「惯性定理」（Sylvester’s Law of Inertia）告诉我们，一个给定的**实二次型** ，无论经过哪种**可逆线性变换** 化为它的**实规范形**，这个规范形都是唯一的。它其实揭示了二次型在**可逆线性变换**（相当于选择不同的基底或坐标系）下的一个本质属性。比如一个二次型可以描述一个二次曲面，比如椭球、双曲面等。惯性定理说的是，无论你如何「拉伸」或「扭曲」坐标系，只要变换是可逆的，这个曲面的基本「形状」——有多少个方向是「凸」的（对应正惯性指数p）、有多少个方向是「凹」的（对应负惯性指数n），以及有多少个方向是「平」的（对应零惯性指数q）——是绝对不会改变的。

| 对称：$S^T = S = Q\Lambda Q^T$                   | 实数特征值                                             | 正交 $x_i^T x_j = 0$                                            |      |                               |
| --------------------------------------------- | ------------------------------------------------- | ------------------------------------------------------------- | ---- | ----------------------------- |
| 正交：$Q^T = Q^{-1}$                             | 所有的$                                              | \lambda                                                       | = 1$ | 正交 $\overline{x}_i^T x_j = 0$ |
| 反对称：$A^T = -A$                                | 虚数$\lambda's$                                     | 正交 $\overline{x}_i^T x_j = 0$                                 |      |                               |
| 复数厄米：$\overline{S}^T = S$                     | 实数$\lambda's$                                     | 正交 $\overline{x}_i^T x_j = 0$                                 |      |                               |
| 正定：$x^TSx > 0$                                | 所有的$\lambda > 0$                                  | 由于$S^T = S$，正交                                                |      |                               |
| 马尔可夫：$m_{ij} > 0$ $\sum_{i=1}^{n} m_{ij} = 1$ | $\lambda_{max} = 1$                               | 稳定状态$x > 0$                                                   |      |                               |
| 相似：$A = BCB^{-1}$                             | $\lambda(A) = \lambda(C)$                         | $B$乘$C$的特征向量                                                  |      |                               |
| 投影：$P = P^2 = P^T$                            | $\lambda = 1; 0$                                  | 列空间；零空间                                                       |      |                               |
| 平面旋转：余弦-正弦                                    | $e^{i\theta}$与$e^{-i\theta}$                      | $x = (1, i)$与$(1, -i)$                                        |      |                               |
| 镜射：$I - 2uu^T$                                | $\lambda = -1, 1, ..., 1$                         | $u$，整个平面$u^\perp$                                             |      |                               |
| 秩一：$uv^T$                                     | $\lambda = v^Tu, 0, ..., 0$                       | $u$，整个平面$u^\perp$                                             |      |                               |
| 逆矩阵：$A^{-1}$                                  | $1/\lambda(A)$                                    | 维持$A$的特征向量                                                    |      |                               |
| 平移：$A + cI$                                   | $\lambda(A) + c$                                  | 维持$A$的特征向量                                                    |      |                               |
| 稳定次方：$A^n \to 0$                              | 全部$                                               | \lambda                                                       | < 1$ | 任意特征向量                        |
| 稳定指数：$e^{At} \to 0$                           | 全部$\text{Re}\lambda < 0$                          | 任意特征向量                                                        |      |                               |
| 循环排列：$P_{i,i+1} = 1, P_{n1} = 1$              | $\lambda_k = e^{\frac{2\pi ik}{n}} = (1$的根$)$     | $x_k = (1, \lambda_k, ..., \lambda_k^{n-1})$                  |      |                               |
| 循环行列式：$c_0I + c_1P + ...$                     | $\lambda_k = c_0 + c_1e^{\frac{2\pi k}{n}} + ...$ | $x_k = (1, \lambda_k, ..., \lambda_k^{n-1})$                  |      |                               |
| 三对角：对角线是$-1, 2, -1$                           | $\lambda_k = 2 - 2\cos(\frac{k\pi}{n+1})$         | $x_k = (\sin(\frac{k\pi}{n+1}), \cos(\frac{k\pi}{n+1}), ...)$ |      |                               |
| 可对角化：$A = X\Lambda X^{-1}$                    | $\Lambda$的对角线                                     | $X$的列是无关                                                      |      |                               |
| 舒尔：$A = QTQ^{-1}$                             | 三角$T$的对角线                                         | 若$A^TA = AA^T$，$Q$的列                                          |      |                               |
| 若尔当：$A = BJB^{-1}$                            | $J$的对角线                                           | 每个方块一个特征向量                                                    |      |                               |
| SVD：$A = U\Sigma V^T$                         | 在$\Sigma$有$r$个奇异值                                 | 在$V, U$的$A^TA, AA^T$的特征向量                                     |      |                               |
## 矩阵的关系，不变量
[(4 封私信 / 82 条消息) 矩阵的等价，相似，合同 - 知乎](https://zhuanlan.zhihu.com/p/262978692)
等价（只有秩相同）–>合同（秩和正负惯性指数相同）–>相似（秩，正负惯性指数，特征值均相同），矩阵亲密关系的一步步深化。
广义特征分解：$Av=\lambda bv$ 1. 对 $B$ 做Cholesky分解，写成 $B = LL^T$。 2. 定义一个新矩阵 $C = L^{-1} A (L^{-1})^T$，问题就变成 $C(L^T v) = \lambda (L^T v)$。 3. 对 $C$ 做普通特征分解，得到特征值 $\lambda$ 和特征向量 $w = L^T v$，然后解出 $v = (L^T)^{-1} w$。广义特征向量v指示了两个椭圆的共同主轴方向。而广义特征值$\lambda$则表示在这些共同主轴上， A和B的缩放比例之间的关系。
## 矩阵的分解
### 针对解方程
利用上、下三角阵便于回代。
初等行变换矩阵用矩阵乘向量、行视角点积理解起来最快。行交换矩阵就是把单位矩阵的行交换一下。注意初等行变换相当于对原来的列空间、行空间做线性组合，不会影响矩阵的秩。
分块消元：方块消元 $\begin{bmatrix} I & 0 \\ -CA^{-1} & I \end{bmatrix} \begin{bmatrix} A & B \\ C & D \end{bmatrix} = \begin{bmatrix} A & B \\ 0 & D - CA^{-1}B \end{bmatrix}$ 右下角称之为舒尔补充
LU分解-高斯消元法的记录板：从A到U完成前向消元，上三角阵U从下往上依次解并代入上面一个式子，形成反向代入。之所以选择L消元逆矩阵使用，是因为前向消元过程中1加到2,2加到3，因此1到3存在耦合，有多余的项；逆向过程，2到3,1到2，这些步骤是没有耦合的，得到的矩阵更为整洁。A=LU，没有交换行的消元法，两个三角阵相当于双级跳、两次都可以直接代入计算，其中L是一个下三角矩阵（通常主对角线为 1），记录了消元过程中各个消元因子，起到消除变量耦合的作用；U是一个上三角矩阵，代表经过消元后保留下来的系数，体现最终不同变量之间的作用。上三角矩阵对角线上的元素被称为主元（Pivot），主元的大小决定了空间在对应维度上的缩放比例。如果主元小于1，则空间在该维度上被压缩；反之，则被拉伸。而非对角线上的元素则代表了剪切（Shear）变换。在工程操作时，先对Ax=b执行前向消元分解把L算出来，然后用反向代入法求解Lc=b，得出的c代入并反向代入求解Ux=c。注意到L的对角线元素均为1，但是U不是，为了更好的平衡，把U给再拆出去一个对角矩阵D让它对角线元素为1，这便是LDU分解。LDU分解要求L和U主对角线元素均为1，只负责剪切，D只负责缩放，因此是“剪切-缩放-剪切”操作。计算方法-先行后列，先U后L，U减紧凑上左，L减完还得除个对角元。好处在于利用D可以捕捉对称矩阵的对称性，对称矩阵S=LDLT。
PA=LU：事先先进行行交换。
QR分解-施密特正交化的矩阵表示：(格莱姆-施密特) 从无关向量$a_1, \ldots, a_n$，格莱姆-施密特创建正交单位向量$q_1, \ldots, q_n$（减去投影可以找到它们，通过它们可以算出R）。这些列构成的矩阵满足$A = QR$，则$R = Q^T A$是上三角，因为后面的$q's$与较早的$a's$正交。A=QR，Q是正交矩阵，R是上三角矩阵。先找到q，再找到r。Q 的列向量是通过 Gram-Schmidt 正交化过程从 A 的列向量生成的一组**标准正交基**（Orthonormal Basis），而 R 则记录了正交化过程中**原始向量在新基下的线性组合系数**。正交化分解后最小二乘法可得到简化最小二乘 $R^T R \hat{x} = R^T Q^T b$ 或 $R \hat{x} = Q^T b$ 或 $\hat{x} = R^{-1} Q^T b$。
Cholesky 分解-对称正定方阵的特定优化：$A=LL^T$ ，其中下三角矩阵L对角元为正且唯一。使用归纳法可以证明分解的存在性。从几何上看，正定矩阵对应超椭球，Cholesky 分解的 L矩阵对应于将超椭球的主轴旋转至与坐标轴方向对齐，并对其进行缩放，使其变成一个标准球。
LDLT分解-针对A对称但不定的情况：$A=LDL^T$ 当所有前主子矩阵非奇异时存在且唯一，其中是L单位下三角矩阵，D是对角矩阵，对角元素可正、可负、可零。「剪切-缩放-剪切」操作。L可以看作是一个坐标变换矩阵，它将原始坐标系转换为一个新的坐标系。在这个新的坐标系下，二次曲面的形状更加简单。 D是一个对角矩阵，它的对角线元素对应于新坐标系下各个方向上的缩放因子。正的对角线元素对应于椭圆方向（曲面在该方向上是有界的或封闭的），负的对角线元素对应于双曲方向（曲面在该方向上是无界的或开放的）。 LDLT 分解将双曲面分离为双曲方向（对应  中负的元素）和椭圆方向（对应  中正的元素）。LT描述了双曲面在各个方向上的倾斜程度。
## 内积、转置与对偶空间
比较难以理解的是向量的内积与外积，理论上它们是矩阵乘法的抽象产物。转置矩阵是伴随变换，在内积的意义上的“逆矩阵”，$(Au) \cdot v = u \cdot (A^{T}v)$ ，比如u在原空间、v在像空间、转置相当于把v拉回到原空间并且保持内积。从奇异值分解角度，转置的几何效果是：**保持相同的缩放因子（奇异值不变），但交换了输入和输出空间的方向（由左、右奇异向量定义）**。所谓对偶空间，就是某种“逆矩阵”，与某种线性泛函相提并论。
定义函数的内积，利用分部积分，可得到微分算子是反对称的，即AT=-A。
行空间与零空间正交，列空间与左零空间正交，能看出对偶的感觉，反着的。
$Ax = \begin{bmatrix} \text{行 1} \\ \vdots \\ \text{行 } m \end{bmatrix} \begin{bmatrix} x \end{bmatrix} = \begin{bmatrix} 0 \\ \vdots \\ 0 \end{bmatrix}$ $\leftarrow (\text{行 1}) \cdot x \text{ 是零}$ $\leftarrow (\text{行 } m) \cdot x \text{ 是零}$ 
点在于每一个 $x$ 可以分成一个行空间分量 $x_r$ 与一个零空间分量 $x_n$。图 4.3 显示 $Ax = Ax_r + Ax_n$ 发生了什么: - 零空间分量走到零: $Ax_n = 0$。 - 行空间分量走到列空间: $Ax_r = Ax$。 每个向量都走到列空间！
![高等代数/attachments/Pasted image 20250703101921.png](/img/user/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/attachments/Pasted%20image%2020250703101921.png)
排列矩阵：是一种特殊的正交矩阵，P具有单位矩阵I的任意顺序的行，其实就是行交换矩阵乘在一起。注意P-1=PT，因为翻转过来那两个1会碰在一起，其余部分都没有值，也就是PPT=I。更直观的证明是，把P视为行交换矩阵的乘积，注意每个单位行交换都是对称的，所以转置刚好把顺序逆过来，这就很显然了。